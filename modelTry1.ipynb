{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: The, POS: DET, Dependency: det\n",
      "Token: professor, POS: NOUN, Dependency: nsubj\n",
      "Token: ,, POS: PUNCT, Dependency: punct\n",
      "Token: who, POS: PRON, Dependency: nsubj\n",
      "Token: was, POS: AUX, Dependency: relcl\n",
      "Token: extremely, POS: ADV, Dependency: advmod\n",
      "Token: knowledgeable, POS: ADJ, Dependency: acomp\n",
      "Token: ,, POS: PUNCT, Dependency: punct\n",
      "Token: provided, POS: VERB, Dependency: ROOT\n",
      "Token: a, POS: DET, Dependency: det\n",
      "Token: thorough, POS: ADJ, Dependency: amod\n",
      "Token: lecture, POS: NOUN, Dependency: dobj\n",
      "Token: on, POS: ADP, Dependency: prep\n",
      "Token: text, POS: NOUN, Dependency: compound\n",
      "Token: simplification, POS: NOUN, Dependency: pobj\n",
      "Token: ., POS: PUNCT, Dependency: punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"The professor, who was extremely knowledgeable, provided a thorough lecture on text simplification.\"\n",
    "\n",
    "# Process the sentence\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Print tokens, parts of speech, and dependencies\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: One of the most powerful techniques for studying the function of a gene is to disrupt the expression of that gene using genetic engineering strategies such as targeted recombination or viral integration of gene trap cassettes. The tremendous utility of these tools was recognized this year with the awarding of the Nobel Prize in Physiology or Medicine to Capecchi, Evans, and Smithies for their pioneering work in targeted recombination mutagenesis in mammals. Another noteworthy discovery made nearly a decade ago was the identification of a novel class of noncoding genes called microRNAs. MicroRNAs are among the largest known classes of regulatory elements with more than 1000 predicted to exist in the mouse genome. Over 50 of known microRNAs are located within introns of coding genes. Given that currently about half of the genes in mouse have been knocked out, we investigated the possibility that intronic microRNAs may have been coincidentally deleted or disrupted in some of these mouse models. We searched published murine knockout studies and gene trap embryonic stem cell line databases for cases where a microRNA was located within or near the manipulated genomic loci, finding almost 200 cases where microRNA expression may have been disrupted along with another gene. Our results draw attention to the need for careful planning in future knockout studies to minimize the unintentional disruption of microRNAs. These data also raise the possibility that many knockout studies may need to be reexamined to determine if loss of a microRNA contributes to the phenotypic consequences attributed to loss of a proteinencoding gene. In the mouse, stable disruption of a gene is typically accomplished using gene trap mutagenesis or targeted homologous recombination. We wish to communicate the overlooked possibility of unintentionally disrupting microRNA (miRNA) genes along with a targeted gene. Because miRNAs play key roles in many cellular processes, the unintended ablation of these species may have significant consequences that complicate the interpretation of gene knockout studies. Given that many miRNAs are located within introns of longer coding transcripts, we reasoned that a gene trap disrupting a host gene could also alter miRNA expression in one of two ways. The trapping cassette could either ablate miRNA expression with a terminal polyadenylation sequence or overexpress an miRNA via an internal promoter. To determine the potential extent of these unintended changes in miRNA expression, we compared the genomic position all mouse gene traps listed in the International Gene Trap Consortium. The boundaries of the deleted loci were bioinformatically verified for each study. Our analysis of the IGTC database revealed 98 annotated or candidate miRNAs potentially misregulated in 420 gene trap cell lines , there were also numerous studies describing the deletion of regions immediately upstream , or in the promoter of the host gene (4 cases). MiRNAs have been shown to be transcribed in conjunction with a host transcript or from an independent promoter. Therefore, the disruption of host promoters or of regions adjacent to miRNAs may compromise promoter andor enhancer sites for these miRNAs. While 71 of the studies in our analysis were published prior to the expansion of the miRNA field in 2002, the fact that 90 were published since may indicate that miRNAs in targeted loci continue to be overlooked. To avoid inadvertent doubleknockout scenarios, we wish to alert investigators to consider noncoding elements in the locus to be deleted. Because not all noncoding elements have been annotated, it may be preferable to employ methods that minimize the deletion of endogenous DNA. We also wish to raise the interesting possibility that a number of studies may need to be reevaluated to dissociate the consequences of ablating an miRNA from the consequences of ablating the targeted gene.\n",
      "Simplified sentence: one of the to the highest degree knock-down technique for perusal the mathematical function of angstrom cistron be to interrupt the look of that cistron exploitation familial technology scheme such arsenic target recombination Oregon viral integrating of cistron snare cassette . The enormous public utility of these tool Washington acknowledge this twelvemonth with the award of the Alfred Nobel prize inch physiology Oregon medicine to Capecchi , Herbert McLean Evans , and forge for their pioneer piece of work inch target recombination mutagenesis inch mammal . another notable find make about angstrom decennary agone Washington the designation of angstrom fresh category of noncoding gene name microRNAs . MicroRNAs ar among the large know class of regulative component with More than thousand predict to be inch the shiner genome . over fifty of know microRNAs ar locate inside intron of cryptography gene . given that presently astir one-half of the gene inch shiner rich person be knock come out of the closet , we investigate the possibleness that intronic microRNAs May rich person be coincidently delete Oregon interrupt inch approximately of these shiner model . We search print murine smasher survey and cistron snare embryologic root electric cell argumentation database for case where angstrom microRNA Washington locate inside Oregon approach the manipulate genomic venue , determination about two hundred case where microRNA look May rich person be interrupt on with some other cistron . Our consequence drawing card attending to the demand for heedful preparation inch hereafter smasher survey to minimise the unwilled break of microRNAs . These information besides rise the possibleness that many smasher survey May demand to beryllium review to find if deprivation of angstrom microRNA lend to the phenotypical consequence impute to deprivation of angstrom proteinencoding cistron . inch the shiner , stalls break of angstrom cistron be typically carry through exploitation cistron snare mutagenesis Oregon target homologous recombination . We wishing to pass on the overlook possibleness of accidentally interrupt microRNA ( miRNA ) gene on with angstrom target cistron . Because miRNAs drama tonality function inch many cellular procedure , the unintended extirpation of these coinage May rich person important consequence that perplex the reading of cistron smasher survey . given that many miRNAs ar locate inside intron of thirster cryptography transcript , we reason that angstrom cistron snare interrupt angstrom horde cistron could besides change miRNA look inch 1 of 2 shipway . The caparison cassette could either ablate miRNA look with angstrom terminus polyadenylation chronological sequence Oregon overexpress Associate in Nursing miRNA via Associate in Nursing intragroup booster . To find the potentiality extent of these unintended change inch miRNA look , we compare the genomic place wholly shiner cistron trap list inch the international gene trap consortium . The boundary of the delete venue be bioinformatically verify for to each one survey . Our analytic thinking of the IGTC database uncover ninety-eight annotate Oregon campaigner miRNAs potentially misregulated inch 420 cistron snare electric cell line , at that place be besides legion survey describe the omission of region instantly upriver , Oregon inch the booster of the horde cistron ( four case ) . MiRNAs rich person be show to beryllium transcribe inch concurrence with angstrom horde copy Oregon from Associate in Nursing mugwump booster . therefore , the break of horde promoter Oregon of region next to miRNAs May via media booster andor foil site for these miRNAs . while seventy-one of the survey inch our analytic thinking be print anterior to the enlargement of the miRNA battlefield inch 2002 , the fact that ninety be print since May bespeak that miRNAs inch target venue go on to beryllium overlook . To debar accidental doubleknockout scenario , we wishing to qui vive research worker to see noncoding component inch the venue to beryllium delete . Because non wholly noncoding component rich person be annotate , information technology May beryllium preferred to employment method that minimise the omission of endogenic deoxyribonucleic acid . We besides wishing to rise the interest possibleness that angstrom figure of survey May demand to beryllium reassess to disassociate the consequence of ablate Associate in Nursing miRNA from the consequence of ablate the target cistron .\n",
      "3926\n",
      "4503\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Function to get a simpler synonym using WordNet\n",
    "def get_simpler_synonym(word):\n",
    "    synonyms = wordnet.synsets(word)\n",
    "    if not synonyms:\n",
    "        return word  # Return original word if no synonyms found\n",
    "    \n",
    "    # Choose a synonym with a high frequency (more common words are generally simpler)\n",
    "    for syn in synonyms:\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:  # Avoid identical synonyms\n",
    "                return lemma.name().replace(\"_\", \" \")\n",
    "    \n",
    "    return word\n",
    "\n",
    "# Test with a sample sentence\n",
    "parg = \"One of the most powerful techniques for studying the function of a gene is to disrupt the expression of that gene using genetic engineering strategies such as targeted recombination or viral integration of gene trap cassettes. The tremendous utility of these tools was recognized this year with the awarding of the Nobel Prize in Physiology or Medicine to Capecchi, Evans, and Smithies for their pioneering work in targeted recombination mutagenesis in mammals. Another noteworthy discovery made nearly a decade ago was the identification of a novel class of noncoding genes called microRNAs. MicroRNAs are among the largest known classes of regulatory elements with more than 1000 predicted to exist in the mouse genome. Over 50 of known microRNAs are located within introns of coding genes. Given that currently about half of the genes in mouse have been knocked out, we investigated the possibility that intronic microRNAs may have been coincidentally deleted or disrupted in some of these mouse models. We searched published murine knockout studies and gene trap embryonic stem cell line databases for cases where a microRNA was located within or near the manipulated genomic loci, finding almost 200 cases where microRNA expression may have been disrupted along with another gene. Our results draw attention to the need for careful planning in future knockout studies to minimize the unintentional disruption of microRNAs. These data also raise the possibility that many knockout studies may need to be reexamined to determine if loss of a microRNA contributes to the phenotypic consequences attributed to loss of a proteinencoding gene. In the mouse, stable disruption of a gene is typically accomplished using gene trap mutagenesis or targeted homologous recombination. We wish to communicate the overlooked possibility of unintentionally disrupting microRNA (miRNA) genes along with a targeted gene. Because miRNAs play key roles in many cellular processes, the unintended ablation of these species may have significant consequences that complicate the interpretation of gene knockout studies. Given that many miRNAs are located within introns of longer coding transcripts, we reasoned that a gene trap disrupting a host gene could also alter miRNA expression in one of two ways. The trapping cassette could either ablate miRNA expression with a terminal polyadenylation sequence or overexpress an miRNA via an internal promoter. To determine the potential extent of these unintended changes in miRNA expression, we compared the genomic position all mouse gene traps listed in the International Gene Trap Consortium. The boundaries of the deleted loci were bioinformatically verified for each study. Our analysis of the IGTC database revealed 98 annotated or candidate miRNAs potentially misregulated in 420 gene trap cell lines , there were also numerous studies describing the deletion of regions immediately upstream , or in the promoter of the host gene (4 cases). MiRNAs have been shown to be transcribed in conjunction with a host transcript or from an independent promoter. Therefore, the disruption of host promoters or of regions adjacent to miRNAs may compromise promoter andor enhancer sites for these miRNAs. While 71 of the studies in our analysis were published prior to the expansion of the miRNA field in 2002, the fact that 90 were published since may indicate that miRNAs in targeted loci continue to be overlooked. To avoid inadvertent doubleknockout scenarios, we wish to alert investigators to consider noncoding elements in the locus to be deleted. Because not all noncoding elements have been annotated, it may be preferable to employ methods that minimize the deletion of endogenous DNA. We also wish to raise the interesting possibility that a number of studies may need to be reevaluated to dissociate the consequences of ablating an miRNA from the consequences of ablating the targeted gene.\"\n",
    "complex_sentences = sent_tokenize(parg)\n",
    "\n",
    "# Simplify each word in each sentence\n",
    "simplified_sentence = []\n",
    "for sentence in complex_sentences:\n",
    "    for word in word_tokenize(sentence):\n",
    "        simplified_word = get_simpler_synonym(word)\n",
    "        simplified_sentence.append(simplified_word)\n",
    "\n",
    "print(\"Original sentence:\", parg)\n",
    "print(\"Simplified sentence:\", \" \".join(simplified_sentence))\n",
    "print(len(parg))\n",
    "print(len(\" \".join(simplified_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simpler Sentences:\n",
      "One of the most powerful techniques for studying the function of a gene is to disrupt the expression of that gene using genetic engineering strategies such as targeted recombination or viral integration of gene trap cassettes. The tremendous utility of these tools was recognized this year with the awarding of the Nobel Prize in Physiology or Medicine to Capecchi.\n",
      "Evans.\n",
      "Smithies for their pioneering work in targeted recombination mutagenesis in mammals. Another noteworthy discovery made nearly a decade ago was the identification of a novel class of noncoding genes called microRNAs. MicroRNAs are among the largest known classes of regulatory elements with more than 1000 predicted to exist in the mouse genome. Over 50 of known microRNAs are located within introns of coding genes. Given that currently about half of the genes in mouse have been knocked out.\n",
      "we investigated the possibility that intronic microRNAs may have been coincidentally deleted or disrupted in some of these mouse models. We searched published murine knockout studies.\n",
      "gene trap embryonic stem cell line databases for cases where a microRNA was located within or near the manipulated genomic loci.\n",
      "finding almost 200 cases where microRNA expression may have been disrupted along with another gene. Our results draw attention to the need for careful planning in future knockout studies to minimize the unintentional disruption of microRNAs. These data also raise the possibility that many knockout studies may need to be reexamined to determine if loss of a microRNA contributes to the phenotypic consequences attributed to loss of a proteinencoding gene. In the mouse.\n",
      "stable disruption of a gene is typically accomplished using gene trap mutagenesis or targeted homologous recombination. We wish to communicate the overlooked possibility of unintentionally disrupting microRNA (miRNA) genes along with a targeted gene. Because miRNAs play key roles in many cellular processes.\n",
      "the unintended ablation of these species may have significant consequences that complicate the interpretation of gene knockout studies. Given that many miRNAs are located within introns of longer coding transcripts.\n",
      "we reasoned that a gene trap disrupting a host gene could also alter miRNA expression in one of two ways. The trapping cassette could either ablate miRNA expression with a terminal polyadenylation sequence or overexpress an miRNA via an internal promoter. To determine the potential extent of these unintended changes in miRNA expression.\n",
      "we compared the genomic position all mouse gene traps listed in the International Gene Trap Consortium. The boundaries of the deleted loci were bioinformatically verified for each study. Our analysis of the IGTC database revealed 98 annotated or candidate miRNAs potentially misregulated in 420 gene trap cell lines.\n",
      "there were also numerous studies describing the deletion of regions immediately upstream.\n",
      "or in the promoter of the host gene (4 cases). MiRNAs have been shown to be transcribed in conjunction with a host transcript or from an independent promoter. Therefore.\n",
      "the disruption of host promoters or of regions adjacent to miRNAs may compromise promoter andor enhancer sites for these miRNAs. While 71 of the studies in our analysis were published prior to the expansion of the miRNA field in 2002.\n",
      "the fact that 90 were published since may indicate that miRNAs in targeted loci continue to be overlooked. To avoid inadvertent doubleknockout scenarios.\n",
      "we wish to alert investigators to consider noncoding elements in the locus to be deleted. Because not all noncoding elements have been annotated.\n",
      "it may be preferable to employ methods that minimize the deletion of endogenous DNA. We also wish to raise the interesting possibility that a number of studies may need to be reevaluated to dissociate the consequences of ablating an miRNA from the consequences of ablating the targeted gene..\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to split a complex sentence into simpler sentences\n",
    "def split_complex_sentence(sentence):\n",
    "    # Split based on commas or conjunctions (simple rule-based approach)\n",
    "    parts = re.split(r',| and | but | which | who ', sentence)\n",
    "    return [part.strip() + \".\" for part in parts if part]\n",
    "\n",
    "# Test with a complex sentence\n",
    "complex_sentence = \"The professor, who was extremely knowledgeable, provided a thorough lecture on text simplification, which was very helpful.\"\n",
    "\n",
    "simpler_sentences = split_complex_sentence(parg)\n",
    "print(\"Simpler Sentences:\")\n",
    "for sent in simpler_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readability score (Flesch-Kincaid grade level): 7.8\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "\n",
    "# Simplified sentence\n",
    "simplified_text = \"The professor was knowledgeable. He gave a lecture on text simplification.\"\n",
    "\n",
    "# Calculate Flesch-Kincaid readability score\n",
    "readability_score = textstat.flesch_kincaid_grade(simplified_text)\n",
    "print(f\"Readability score (Flesch-Kincaid grade level): {readability_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: professor\n",
      "Suggested simplifications: ['king', 'governor', 'speaker', 'queen']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Load a pre-trained fill-mask model (e.g., BERT)\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "\n",
    "# Function to generate simpler synonyms using BERT and WordNet\n",
    "def generate_simplifications(sentence, target_word):\n",
    "    # Replace the target word with BERT's mask token\n",
    "    masked_sentence = sentence.replace(target_word, \"[MASK]\")\n",
    "    \n",
    "    # Get predictions for the masked word\n",
    "    predictions = fill_mask(masked_sentence)\n",
    "    \n",
    "    # Filter predictions to ensure they're simpler synonyms\n",
    "    simpler_words = []\n",
    "    for pred in predictions:\n",
    "        predicted_word = pred[\"token_str\"]\n",
    "        # Check if the predicted word is simpler using WordNet frequency\n",
    "        if wordnet.synsets(predicted_word) and len(predicted_word) < len(target_word):\n",
    "            simpler_words.append(predicted_word)\n",
    "    \n",
    "    return simpler_words\n",
    "\n",
    "# Example sentence and target word\n",
    "sentence = \"The professor delivered an elaborate presentation on the subject.\"\n",
    "target_word = \"professor\"\n",
    "\n",
    "# Get simplifications\n",
    "simplifications = generate_simplifications(sentence, target_word)\n",
    "print(f\"Original word: {target_word}\")\n",
    "print(f\"Suggested simplifications: {simplifications}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the most powerful techniques for studying the function of a gene is to disrupt the expression of that gene using genetic engineering strategies such as targeted recombination or viral integration of gene trap cassettes.\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "The tremendous utility of these tools was recognized this year with the awarding of the Nobel Prize in Physiology or Medicine to Capecchi, Evans, and Smithies for their pioneering work in targeted recombination mutagenesis in mammals.\n",
      "Another noteworthy discovery made nearly a decade ago was the identification of a novel class of noncoding genes called microRNAs.\n",
      "MicroRNAs are among the largest known classes of regulatory elements with more than 1000 predicted to exist in the mouse genome.\n",
      "Over 50 of known microRNAs are located within introns of coding genes.\n",
      "Given that currently about half of the genes in mouse have been knocked out, we investigated the possibility that intronic microRNAs may have been coincidentally deleted or disrupted in some of these mouse models.\n",
      "Error processing word 'mouse' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'mouse' in context: list indices must be integers or slices, not str\n",
      "We searched published murine knockout studies and gene trap embryonic stem cell line databases for cases where a microRNA was located within or near the manipulated genomic loci, finding almost 200 cases where microRNA expression may have been disrupted along with another gene.\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'microRNA' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'microRNA' in context: list indices must be integers or slices, not str\n",
      "Our results draw attention to the need for careful planning in future knockout studies to minimize the unintentional disruption of microRNAs.\n",
      "These data also raise the possibility that many knockout studies may need to be reexamined to determine if loss of a microRNA contributes to the phenotypic consequences attributed to loss of a proteinencoding gene.\n",
      "In the mouse, stable disruption of a gene is typically accomplished using gene trap mutagenesis or targeted homologous recombination.\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "We wish to communicate the overlooked possibility of unintentionally disrupting microRNA (miRNA) genes along with a targeted gene.\n",
      "Because miRNAs play key roles in many cellular processes, the unintended ablation of these species may have significant consequences that complicate the interpretation of gene knockout studies.\n",
      "Given that many miRNAs are located within introns of longer coding transcripts, we reasoned that a gene trap disrupting a host gene could also alter miRNA expression in one of two ways.\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'miRNA' in context: list indices must be integers or slices, not str\n",
      "The trapping cassette could either ablate miRNA expression with a terminal polyadenylation sequence or overexpress an miRNA via an internal promoter.\n",
      "Error processing word 'miRNA' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'miRNA' in context: list indices must be integers or slices, not str\n",
      "To determine the potential extent of these unintended changes in miRNA expression, we compared the genomic position all mouse gene traps listed in the International Gene Trap Consortium.\n",
      "The boundaries of the deleted loci were bioinformatically verified for each study.\n",
      "Our analysis of the IGTC database revealed 98 annotated or candidate miRNAs potentially misregulated in 420 gene trap cell lines , there were also numerous studies describing the deletion of regions immediately upstream , or in the promoter of the host gene (4 cases).\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "Error processing word ',' in context: list indices must be integers or slices, not str\n",
      "Error processing word ',' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'gene' in context: list indices must be integers or slices, not str\n",
      "MiRNAs have been shown to be transcribed in conjunction with a host transcript or from an independent promoter.\n",
      "Therefore, the disruption of host promoters or of regions adjacent to miRNAs may compromise promoter andor enhancer sites for these miRNAs.\n",
      "Error processing word 'miRNAs' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'promoter' in context: list indices must be integers or slices, not str\n",
      "While 71 of the studies in our analysis were published prior to the expansion of the miRNA field in 2002, the fact that 90 were published since may indicate that miRNAs in targeted loci continue to be overlooked.\n",
      "Error processing word 'miRNA' in context: list indices must be integers or slices, not str\n",
      "To avoid inadvertent doubleknockout scenarios, we wish to alert investigators to consider noncoding elements in the locus to be deleted.\n",
      "Because not all noncoding elements have been annotated, it may be preferable to employ methods that minimize the deletion of endogenous DNA.\n",
      "We also wish to raise the interesting possibility that a number of studies may need to be reevaluated to dissociate the consequences of ablating an miRNA from the consequences of ablating the targeted gene.\n",
      "Error processing word 'consequences' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'ablating' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'consequences' in context: list indices must be integers or slices, not str\n",
      "Error processing word 'ablating' in context: list indices must be integers or slices, not str\n",
      "Simplified Article:\n",
      " One of the most common methods for studying the function of a gene is to study the function of that gene using gene control methods such as gene targeting or viral invasion of gene trap cassettes. The great power of these tools was shown this year with the award of the Nobel Prize in biology or anatomy to both smith and fisher for their seminal work in dna cellular studies in mammals. Another important work made nearly a year ago was the discovery of a new class of rna rna called microRNAs. MicroRNAs are among the oldest known set of rna rna with more than 100 species to be in the mouse genome. Over 50 of known microRNAs are found within introns of human genes Given that currently about half of the mrna in mouse have been worked out, we consider the hypothesis that some microRNAs may have been either found or altered in some of these mouse genes We have published gene genetic mice and gene or or or cell line studies for cases where a microRNA was found within or near the same gene dna or almost no cases where microRNA function may have been altered along with another gene. Our results draw attention to the need for careful design in future animal steps to prevent the potential effects of microRNAs. These data also pose the concern that many other mice may need to be conducted to see if loss of a microRNA leads to the negative changes due to loss of a specific gene. In the lab stable disruption of a gene is usually achieved using gene trap formation or by nuclear selection We wish to avoid the possible problem of potentially targeting rna target genes along with a related gene. Because miRNAs play key role in many cellular processes the gene effects of these genes may have important effects that affect the outcome of gene knockout studies. Given that many genes are found within region of longer mrna genes we know that a gene by in a host gene could also alter miRNA function in one of two ways. The dna agent could either ablate miRNA molecules with a single termination site or generate an miRNA via an internal promoter. To see the potential cause of these small changes in miRNA expression we compare the genomic position all four dna traps found in the International Gene Trap Consortium. The locations of the deleted loci were then defined for each study. Our review of the IGTC genome found 98 known or modified miRNAs were expressed in 420 gene trap cell lines , there were also several errors involving the number of genes either before , or in the absence of the host gene (4 cases). MiRNAs have been shown to be expressed in tandem with a host gene or from an alternate gene however the lack of host genes or of genes related to miRNAs may affect promoter or binding sites for these miRNAs. While 71 of the data in our field were published due to the creation of the miRNA field in 2002, the fact that 90 were published since may suggest that gaps in many loci continue to be overlooked. To avoid such error behavior we wish to ask us to any all errors in the data to be deleted. Because not all dna genes have been found it may be best to use methods that avoid the amount of a DNA. We also wish to raise the interesting issue that a number of genes may need to be conducted to separate the consequences of ablating an miRNA from the consequences of ablating the same gene.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from wordfreq import word_frequency\n",
    "\n",
    "def is_complex_word(word, threshold=0.0001):\n",
    "    \"\"\"\n",
    "    Determines if a word is complex based on its frequency.\n",
    "    \n",
    "    Args:\n",
    "        word (str): The word to check.\n",
    "        threshold (float): Minimum frequency threshold. Lower = rarer = complex.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the word is complex, False otherwise.\n",
    "    \"\"\"\n",
    "    word = word.lower()  # Ensure case-insensitivity\n",
    "    frequency = word_frequency(word, 'en')  # Get word frequency\n",
    "    return frequency < threshold  # Complex if frequency is below threshold\n",
    "\n",
    "# Load NLP and similarity models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "sentence_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to calculate semantic similarity\n",
    "def semantic_similarity(original, simplified):\n",
    "    embeddings = sentence_model.encode([original, simplified], convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
    "    return similarity.item()\n",
    "\n",
    "# Function to simplify words while preserving meaning\n",
    "def simplify_word(word, context):\n",
    "    masked_sentence = context.replace(word, \"[MASK]\")\n",
    "    predictions = fill_mask(masked_sentence)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Get predictions for the masked word\n",
    "        predictions = fill_mask(masked_sentence)\n",
    "        \n",
    "        # Ensure predictions are in the expected list of dictionaries format\n",
    "        if not isinstance(predictions, list):\n",
    "            return word  # Return original word if predictions are not as expected\n",
    "        \n",
    "        # Iterate through predictions to find simpler synonyms\n",
    "        for pred in predictions:\n",
    "            simplified_word = pred[\"token_str\"]\n",
    "            if wordnet.synsets(simplified_word) and len(simplified_word) < len(word):\n",
    "                # Check semantic similarity to preserve meaning\n",
    "                similarity = semantic_similarity(context, context.replace(word, simplified_word))\n",
    "                if similarity > 0.9:  # Threshold for meaning preservation\n",
    "                    return simplified_word\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{word}' in context: {e}\")\n",
    "        \n",
    "    return word\n",
    "\n",
    "# Function to split sentences\n",
    "def split_sentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return [sent.text for sent in doc.sents]\n",
    "\n",
    "# Function to simplify an article\n",
    "def simplify_article(article):\n",
    "    simplified_article = []\n",
    "    doc = nlp(article)\n",
    "    \n",
    "    for sentence in doc.sents:\n",
    "        print(sentence)\n",
    "        words = sentence.text.split()\n",
    "        simplified_words = [simplify_word(word, sentence.text) if is_complex_word(word) else word for word in words]\n",
    "        simplified_sentence = \" \".join(simplified_words)\n",
    "        simplified_sentences = split_sentence(simplified_sentence)\n",
    "        simplified_article.extend(simplified_sentences)\n",
    "    \n",
    "    return \" \".join(simplified_article)\n",
    "\n",
    "# Example article\n",
    "article = \"\"\"\n",
    "The professor delivered an elaborate and detailed lecture on text simplification, \n",
    "which was extremely beneficial for the students. They found the topic intriguing \n",
    "and intellectually stimulating, although the complexity was challenging.\n",
    "\"\"\"\n",
    "\n",
    "# Simplify the article\n",
    "simplified_output = simplify_article(parg)\n",
    "print(\"Simplified Article:\\n\", simplified_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds1 = load_dataset(\"bogdancazan/wikilarge-text-simplification\")\n",
    "ds2 = load_dataset(\"rahular/simple-wikipedia\")\n",
    "ds3 = load_dataset(\"dongqi-me/SciNews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Tokenizing function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the dataset (Assume 'text' is the field in your dataset)\n",
    "tokenized_datasets = ds2.map(tokenize_function, batched=True)\n",
    "\n",
    "# Prepare for training\n",
    "train_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(1000)])  # Example 1000 samples\n",
    "val_dataset = tokenized_datasets.shuffle(seed=42).select([i for i in range(1000, 1200)])\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=\"./logs\",            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the pre-trained model\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,            # evaluation dataset\n",
    "    tokenizer=tokenizer,                 # tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_text(text):\n",
    "    # Encode input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    # Generate simplified text\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs['input_ids'], max_length=150, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode and return the simplified text\n",
    "    simplified_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return simplified_text\n",
    "\n",
    "# Example usage:\n",
    "scientific_text = \"\"\"Scientists have recently discovered the existence of gravitational waves, which are ripples in spacetime...\n",
    "    These waves are produced by accelerating massive objects such as black holes or neutron stars. The detection of these waves has revolutionized\n",
    "    our understanding of the universe.\"\"\"\n",
    "\n",
    "simplified_text = simplify_text(scientific_text)\n",
    "print(simplified_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
